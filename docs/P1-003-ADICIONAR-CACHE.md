# ğŸ’¾ CorreÃ§Ã£o #24: Adicionar Cache em Endpoints de Stats (P1-003)

> **Guia Completo de ImplementaÃ§Ã£o**  
> **Data:** Outubro 2025  
> **Prioridade:** P1 (Alto)  
> **Categoria:** Performance / Caching  
> **Status:** DocumentaÃ§Ã£o Completa

---

## ğŸ“‹ Ãndice

- [InformaÃ§Ãµes Gerais](#informaÃ§Ãµes-gerais)
- [Contexto e ImportÃ¢ncia](#contexto-e-importÃ¢ncia)
- [AnÃ¡lise Detalhada do Problema](#anÃ¡lise-detalhada-do-problema)
- [SoluÃ§Ã£o Proposta](#soluÃ§Ã£o-proposta)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [Passo a Passo de ImplementaÃ§Ã£o](#passo-a-passo-de-implementaÃ§Ã£o)
- [ValidaÃ§Ã£o e Testes](#validaÃ§Ã£o-e-testes)
- [Troubleshooting](#troubleshooting)
- [Rollback](#rollback)
- [PrÃ³ximos Passos](#prÃ³ximos-passos)

---

## InformaÃ§Ãµes Gerais

### Metadados

| Campo | Valor |
|-------|-------|
| **ID** | P1-003 (originalmente PERF-002) |
| **TÃ­tulo** | Adicionar Cache em Endpoints de Stats |
| **NÃ­vel de Risco** | ğŸŸ¡ BAIXO |
| **Tempo Estimado** | 1-2 horas |
| **Prioridade** | P1 (Alto) |
| **Categoria** | Performance / Caching |
| **Impacto** | Muito Alto (95% reduÃ§Ã£o em queries) |
| **Dificuldade** | MÃ©dia |
| **Arquivos Afetados** | 2 arquivos |

### SÃ­mbolos Usados

- âœ… = AÃ§Ã£o obrigatÃ³ria
- âš ï¸ = Cuidado especial necessÃ¡rio
- ğŸ’¡ = Dica Ãºtil
- ğŸš¨ = Perigo! Leia com atenÃ§Ã£o
- âŒ = CÃ³digo que serÃ¡ removido/alterado
- âœ”ï¸ = CÃ³digo novo/correto

### Arquivos Que SerÃ£o Modificados

```
backend/
â”œâ”€â”€ requirements.txt               [MODIFICAR] - Adicionar cachetools
â””â”€â”€ routes/appointments.py         [MODIFICAR] - Implementar cache em mega_stats
```

---

## Contexto e ImportÃ¢ncia

### O Problema: RecÃ¡lculo Constante

O endpoint `/api/v1/appointments/mega-stats` Ã© chamado frequentemente pelo dashboard (polling a cada 30s), mas **recalcula tudo a cada requisiÃ§Ã£o**, mesmo que os dados nÃ£o tenham mudado:

```python
# ATUAL - SEM CACHE
@router.get("/mega-stats")
def mega_stats(...):
    # Recalcula 4 buckets Ã— 4 queries = sempre vai ao banco
    stats = {
        "today": _count_bucket(...),     # Query ao banco
        "week": _count_bucket(...),      # Query ao banco
        "month": _count_bucket(...),     # Query ao banco
        "nextMonth": _count_bucket(...)  # Query ao banco
    }
    return stats
```

**Por que isso Ã© um problema?**

1. **â±ï¸ DesperdÃ­cio de Recursos:**
   - Dashboard faz polling a cada 30s
   - 1 usuÃ¡rio = 2 requests/minuto = 120 requests/hora
   - 100 usuÃ¡rios = 12.000 requests/hora
   - Todos recalculando os mesmos dados!

2. **ğŸ’¾ Carga DesnecessÃ¡ria no Banco:**
   - 4 queries por request Ã— 12.000 requests = 48.000 queries/hora
   - 95% dessas queries retornam os mesmos dados
   - Banco gasta CPU/memÃ³ria recalculando resultados idÃªnticos

3. **ğŸ“‰ Performance Degradada:**
   - Mais usuÃ¡rios = mais carga
   - Queries lentas afetam todo mundo
   - Sistema nÃ£o escala horizontalmente

### Impacto Real

**CenÃ¡rio Atual (sem cache):**

```
UsuÃ¡rio A (00:00:00): GET /mega-stats â†’ 4 queries ao banco
UsuÃ¡rio A (00:00:30): GET /mega-stats â†’ 4 queries ao banco (mesmos dados!)
UsuÃ¡rio A (00:01:00): GET /mega-stats â†’ 4 queries ao banco (mesmos dados!)
...
UsuÃ¡rio B (00:00:15): GET /mega-stats â†’ 4 queries ao banco (mesmos dados que A!)
UsuÃ¡rio B (00:00:45): GET /mega-stats â†’ 4 queries ao banco (mesmos dados!)

Total em 1 minuto (2 usuÃ¡rios):
- 6 requests
- 24 queries ao banco
- 95% dos dados sÃ£o idÃªnticos
```

**Com Cache (TTL 30s):**

```
UsuÃ¡rio A (00:00:00): GET /mega-stats â†’ 4 queries ao banco â†’ SALVA NO CACHE
UsuÃ¡rio A (00:00:30): GET /mega-stats â†’ CACHE HIT (0 queries!)
UsuÃ¡rio A (00:01:00): GET /mega-stats â†’ 4 queries ao banco â†’ ATUALIZA CACHE
...
UsuÃ¡rio B (00:00:15): GET /mega-stats â†’ CACHE HIT (0 queries!)
UsuÃ¡rio B (00:00:45): GET /mega-stats â†’ CACHE HIT (0 queries!)

Total em 1 minuto (2 usuÃ¡rios):
- 6 requests
- 4 queries ao banco (1Âª request calcula, resto usa cache)
- 83% de reduÃ§Ã£o em queries!
```

### MÃ©tricas de Impacto

| CenÃ¡rio | Requests/hora | Queries sem cache | Queries com cache | ReduÃ§Ã£o |
|---------|---------------|-------------------|-------------------|---------|
| 1 usuÃ¡rio | 120 | 480 | 24 | **-95%** |
| 10 usuÃ¡rios | 1.200 | 4.800 | 240 | **-95%** |
| 100 usuÃ¡rios | 12.000 | 48.000 | 2.400 | **-95%** |
| 1000 usuÃ¡rios | 120.000 | 480.000 | 24.000 | **-95%** |

ğŸ’° **Economia massiva em custos de banco de dados!**

### Por Que Fazer Agora?

- âœ… **Complementa P1-001 e P1-002:** PaginaÃ§Ã£o + N+1 fix + Cache = Sistema extremamente otimizado
- âœ… **Alto Impacto, Baixo Risco:** 95% de ganho com implementaÃ§Ã£o simples
- âœ… **Escalabilidade:** Sistema suporta 100x mais usuÃ¡rios
- âœ… **UX Melhor:** Respostas instantÃ¢neas (cache hit < 1ms)
- âœ… **PreparaÃ§Ã£o para ProduÃ§Ã£o:** Essencial para ambientes multi-usuÃ¡rio

---

## AnÃ¡lise Detalhada do Problema

### CÃ³digo Atual (Sem Cache)

**LocalizaÃ§Ã£o:** `backend/routes/appointments.py:157-220` (apÃ³s P1-002)

```python
@router.get("/mega-stats")
def mega_stats(
    response: Response,
    tenantId: str = Query(...),
    tz: str = Query("America/Recife"),
    db: Session = Depends(get_db),
):
    response.headers["Cache-Control"] = "no-store"

    TZ = ZoneInfo(tz)
    now_local = datetime.now(TZ)

    # CÃ¡lculo de buckets (today, week, month, nextMonth)
    # ... cÃ³digo de cÃ¡lculo de datas ...

    stats = {
        "today": _count_bucket(db, tenantId, today_start, today_end, TZ),
        "week": _count_bucket(db, tenantId, sunday_start, saturday_end, TZ),
        "month": _count_bucket(db, tenantId, month_start, next_month_start, TZ),
        "nextMonth": _count_bucket(db, tenantId, next_month_start, after_next_month_start, TZ),
    }
    
    return stats  # âŒ Sempre recalcula, nunca usa cache
```

### AnÃ¡lise de PadrÃ£o de Acesso

**Dashboard comportamento:**

```javascript
// Frontend - src/hooks/useDashboardMegaStats.ts
useQuery({
    queryKey: ['dashboardMegaStats', tenantId, tz],
    queryFn: async () => { ... },
    staleTime: 30_000,        // 30 segundos
    refetchOnWindowFocus: true // Refetch ao focar na janela
});
```

**PadrÃ£o de requests:**

```
00:00:00 - Request inicial (dashboard abre)
00:00:30 - Auto-refresh (staleTime expirou)
00:01:00 - Auto-refresh
00:01:30 - Auto-refresh
...
```

**Problema:** Backend nÃ£o sabe que dados sÃ£o os mesmos, recalcula sempre.

### Por Que Stats Mudam Lentamente?

**FrequÃªncia de mudanÃ§a:**

| Bucket | Muda Quando | FrequÃªncia TÃ­pica |
|--------|-------------|-------------------|
| **today** | Novo appointment criado/atualizado | ~5-10 min entre mudanÃ§as |
| **week** | Novo appointment na semana | ~10-30 min |
| **month** | Novo appointment no mÃªs | ~20-60 min |
| **nextMonth** | Novo appointment agendado | ~1-3 horas |

**ConclusÃ£o:** Stats sÃ£o **relativamente estÃ¡ticos**, perfeito para cache!

### Oportunidade de Cache

**TTL (Time-To-Live) ideal:**

- **30 segundos:** BalanÃ§o perfeito entre freshness e performance
- Dados "semi-frescos" (delay mÃ¡ximo de 30s)
- 95% de cache hits em cenÃ¡rios normais
- Stats mudam devagar, 30s de delay Ã© aceitÃ¡vel

**Cache hit rate esperado:**

```
Polling a cada 30s com TTL de 30s:

Request 1 (00:00:00): MISS â†’ calcula â†’ salva cache (TTL atÃ© 00:00:30)
Request 2 (00:00:30): MISS â†’ calcula â†’ salva cache (TTL atÃ© 00:01:00)
Request 3 (00:01:00): MISS â†’ calcula â†’ salva cache (TTL atÃ© 00:01:30)

Com mÃºltiplos usuÃ¡rios:

User A (00:00:00): MISS â†’ calcula â†’ salva cache
User B (00:00:10): HIT  â†’ retorna do cache (mesmo bucket de tempo)
User C (00:00:20): HIT  â†’ retorna do cache
User D (00:00:30): MISS â†’ calcula â†’ atualiza cache
User E (00:00:40): HIT  â†’ retorna do cache

Cache Hit Rate: 60-95% dependendo da distribuiÃ§Ã£o de usuÃ¡rios
```

---

## SoluÃ§Ã£o Proposta

### EstratÃ©gia: TTLCache (In-Memory)

Usar **cachetools.TTLCache** - cache em memÃ³ria com expiraÃ§Ã£o automÃ¡tica:

**Vantagens:**
- âœ… Simples de implementar (biblioteca Python pura)
- âœ… Zero dependÃªncias externas (sem Redis, Memcached)
- âœ… Funciona em desenvolvimento e produÃ§Ã£o (single-server)
- âœ… TTL automÃ¡tico (dados expiram automaticamente)
- âœ… Thread-safe (com lock)

**Desvantagens:**
- âŒ NÃ£o funciona em multi-server (cada server tem cache prÃ³prio)
- âŒ Dados perdidos ao reiniciar servidor
- âŒ Limitado Ã  memÃ³ria do processo

**DecisÃ£o:** TTLCache Ã© **perfeito para MVP** e single-server. Redis pode ser adicionado depois se necessÃ¡rio.

### Arquitetura da SoluÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         REQUEST                              â”‚
â”‚   GET /api/v1/appointments/mega-stats?tenantId=X&tz=Y       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    mega_stats()                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. Gerar cache_key(tenantId, tz, date)                     â”‚
â”‚     â†’ "mega_stats:default-tenant:America/Recife:2025-10-31" â”‚
â”‚                                                              â”‚
â”‚  2. Verificar se existe no cache (com lock)                 â”‚
â”‚     â”œâ”€ Cache HIT â†’ Retornar imediatamente                   â”‚
â”‚     â”‚              Header: X-Cache: HIT                      â”‚
â”‚     â”‚              Tempo: < 1ms                              â”‚
â”‚     â”‚                                                        â”‚
â”‚     â””â”€ Cache MISS â†’ Calcular stats                          â”‚
â”‚                     â”‚                                        â”‚
â”‚                     â”œâ”€ _count_bucket(today)    â†’ 1 query    â”‚
â”‚                     â”œâ”€ _count_bucket(week)     â†’ 1 query    â”‚
â”‚                     â”œâ”€ _count_bucket(month)    â†’ 1 query    â”‚
â”‚                     â””â”€ _count_bucket(nextMonth)â†’ 1 query    â”‚
â”‚                                                              â”‚
â”‚                     Salvar no cache (TTL 30s)               â”‚
â”‚                     Header: X-Cache: MISS                    â”‚
â”‚                     Tempo: ~100ms                            â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cache Key Strategy

**Formato:**
```
mega_stats:{tenant_id}:{timezone}:{date_key}
```

**Exemplo:**
```
mega_stats:default-tenant:America/Recife:2025-10-31
```

**Por que incluir date_key?**

- Stats mudam diariamente (midnight crossing)
- Cache automÃ¡tico invalidado ao trocar de dia
- Evita servir stats do dia anterior

**Componentes:**

| Componente | Valor | Por quÃª |
|------------|-------|---------|
| **Prefix** | `mega_stats` | Identifica tipo de dado |
| **tenant_id** | `default-tenant` | Isolamento multi-tenant |
| **timezone** | `America/Recife` | Stats dependem de TZ |
| **date_key** | `2025-10-31` | Invalida automaticamente ao trocar de dia |

### TTL (Time-To-Live)

**Valor escolhido: 30 segundos**

**AnÃ¡lise:**

| TTL | PrÃ³s | Contras | DecisÃ£o |
|-----|------|---------|---------|
| 10s | Dados muito frescos | Cache hit rate menor (~30%) | âŒ Pouco ganho |
| 30s | Bom balanÃ§o | Delay aceitÃ¡vel de atÃ© 30s | âœ… **ESCOLHIDO** |
| 60s | Menos queries | Dados podem estar "stale" | âš ï¸ Ok para alguns casos |
| 5min | MÃ¡ximo ganho | Dados muito desatualizados | âŒ Muito longo |

**Justificativa dos 30s:**

1. Alinha com `staleTime` do React Query no frontend
2. Dados de stats nÃ£o mudam tÃ£o rapidamente
3. 30s de delay Ã© imperceptÃ­vel para o usuÃ¡rio
4. Cache hit rate de 60-95% (excelente)

### Thread Safety

**Problema:** Python Ã© multi-threaded (Uvicorn workers)

**SoluÃ§Ã£o:** Lock para acesso ao cache

```python
import threading

cache_lock = threading.Lock()

# Uso:
with cache_lock:
    cached = stats_cache.get(cache_key)
    if cached:
        return cached
```

**Por quÃª?**

- Previne race conditions
- Cache pode ser acessado simultaneamente por mÃºltiplos requests
- Lock garante atomicidade de leitura/escrita

---

## PrÃ©-requisitos

### Checklist Antes de ComeÃ§ar

- [ ] Backend rodando sem erros
- [ ] Git status limpo
- [ ] Fazer backup: `git add . && git commit -m "checkpoint: before P1-003"`
- [ ] Entender conceito de cache (TTL, cache key, hit/miss)
- [ ] P1-002 implementado (queries otimizadas)
- [ ] Tempo disponÃ­vel: ~1-2 horas

### Conhecimentos NecessÃ¡rios

- ğŸ Python intermediÃ¡rio (decorators, context managers)
- ğŸ“¦ Gerenciamento de dependÃªncias (pip, requirements.txt)
- ğŸ’¾ Conceitos de caching (TTL, invalidaÃ§Ã£o, cache key)
- ğŸ”’ Threading bÃ¡sico (locks, race conditions)

### Ferramentas

- Editor de cÃ³digo (VS Code, Cursor)
- Terminal
- Navegador com DevTools (para verificar headers)

---

## Passo a Passo de ImplementaÃ§Ã£o

> âš ï¸ **IMPORTANTE:** Cache Ã© uma otimizaÃ§Ã£o pura. Se algo der errado, sistema continua funcionando (sÃ³ mais lento).

---

### PASSO 1: Adicionar DependÃªncia cachetools

**PASSO 1.1: Verificar backup**

```bash
git status
git add . && git commit -m "checkpoint: before P1-003 cache implementation"
```

**PASSO 1.2: Abrir requirements.txt**

```bash
code backend/requirements.txt
# OU
cursor backend/requirements.txt
```

**PASSO 1.3: Adicionar cachetools**

**Localizar** o final do arquivo `backend/requirements.txt`:

```
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
pydantic==2.5.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.6
```

**Adicionar** ao final:

```
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
pydantic==2.0.5
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.6
cachetools==5.3.2
```

âš ï¸ **Nota:** Adicionar na Ãºltima linha, versÃ£o especÃ­fica para estabilidade.

**PASSO 1.4: Instalar dependÃªncia**

```bash
cd backend
pip install cachetools==5.3.2
```

**SaÃ­da esperada:**
```
Collecting cachetools==5.3.2
  Using cached cachetools-5.3.2-py3-none-any.whl
Installing collected packages: cachetools
Successfully installed cachetools-5.3.2
```

âœ… **Checkpoint:** DependÃªncia instalada!

---

### PASSO 2: Implementar Cache no Endpoint

**PASSO 2.1: Abrir arquivo de rotas**

```bash
code backend/routes/appointments.py
# OU
cursor backend/routes/appointments.py
```

**PASSO 2.2: Adicionar imports no topo**

**Localizar** a seÃ§Ã£o de imports (linhas 1-9):

```python
from fastapi import APIRouter, Depends, Query, Response, HTTPException
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from typing import List, Optional
from auth.dependencies import get_db
from models.appointment import Appointment
from schemas.appointment import AppointmentCreate, AppointmentUpdate, AppointmentResponse, AppointmentPaginatedResponse
from sqlalchemy import and_, func, case
```

**Adicionar** apÃ³s as Ãºltimas importaÃ§Ãµes:

```python
from fastapi import APIRouter, Depends, Query, Response, HTTPException
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from typing import List, Optional
from auth.dependencies import get_db
from models.appointment import Appointment
from schemas.appointment import AppointmentCreate, AppointmentUpdate, AppointmentResponse, AppointmentPaginatedResponse
from sqlalchemy import and_, func, case
from cachetools import TTLCache  # âœ”ï¸ Novo
import threading  # âœ”ï¸ Novo
```

**PASSO 2.3: Criar cache e lock apÃ³s o router**

**Localizar** a linha:

```python
router = APIRouter(prefix="/v1/appointments", tags=["appointments"])
```

**Adicionar** logo apÃ³s:

```python
router = APIRouter(prefix="/v1/appointments", tags=["appointments"])

# ============================================================================
# CACHE - P1-003
# ============================================================================

# Cache em memÃ³ria com TTL de 30 segundos
# maxsize=100: Armazena atÃ© 100 cache keys diferentes
# ttl=30: Cada entrada expira automaticamente apÃ³s 30 segundos
stats_cache = TTLCache(maxsize=100, ttl=30)

# Lock para garantir thread-safety em acesso ao cache
cache_lock = threading.Lock()

def get_cache_key(tenant_id: str, tz: str) -> str:
    """
    Gera chave de cache Ãºnica para mega_stats.
    
    Formato: mega_stats:{tenant_id}:{tz}:{date}
    
    Inclui data atual para invalidaÃ§Ã£o automÃ¡tica ao trocar de dia.
    """
    now = datetime.now(ZoneInfo(tz))
    date_key = now.strftime('%Y-%m-%d')
    return f"mega_stats:{tenant_id}:{tz}:{date_key}"
```

âœ… **Checkpoint:** Cache e funÃ§Ã£o helper criados!

---

### PASSO 3: Modificar Endpoint mega_stats

**PASSO 3.1: Localizar funÃ§Ã£o mega_stats**

**Buscar** (Ctrl+F): `def mega_stats`

VocÃª verÃ¡ (aproximadamente linha 157):

```python
@router.get("/mega-stats")
def mega_stats(
    response: Response,
    tenantId: str = Query(...),
    tz: str = Query("America/Recife"),
    db: Session = Depends(get_db),
):
    response.headers["Cache-Control"] = "no-store"

    TZ = ZoneInfo(tz)
    now_local = datetime.now(TZ)
    
    # ... resto da funÃ§Ã£o ...
```

**PASSO 3.2: Adicionar lÃ³gica de cache no inÃ­cio**

**Substituir** APENAS o inÃ­cio da funÃ§Ã£o (atÃ© `now_local = datetime.now(TZ)`):

**ANTES:**
```python
@router.get("/mega-stats")
def mega_stats(
    response: Response,
    tenantId: str = Query(...),
    tz: str = Query("America/Recife"),
    db: Session = Depends(get_db),
):
    response.headers["Cache-Control"] = "no-store"

    TZ = ZoneInfo(tz)
    now_local = datetime.now(TZ)
```

**DEPOIS:**
```python
@router.get("/mega-stats")
def mega_stats(
    response: Response,
    tenantId: str = Query(...),
    tz: str = Query("America/Recife"),
    db: Session = Depends(get_db),
):
    """
    Retorna estatÃ­sticas agregadas de appointments.
    
    Cache: TTL 30s (otimizaÃ§Ã£o P1-003)
    - Cache HIT: < 1ms de resposta
    - Cache MISS: ~100ms (calcula e salva no cache)
    """
    cache_key = get_cache_key(tenantId, tz)
    
    # Tentar buscar do cache (thread-safe)
    with cache_lock:
        cached = stats_cache.get(cache_key)
        if cached is not None:
            response.headers["Cache-Control"] = "no-store"
            response.headers["X-Cache"] = "HIT"
            return cached
    
    # Cache miss - calcular stats
    response.headers["Cache-Control"] = "no-store"
    response.headers["X-Cache"] = "MISS"
    
    TZ = ZoneInfo(tz)
    now_local = datetime.now(TZ)
```

âš ï¸ **ATENÃ‡ÃƒO:** Manter o resto da funÃ§Ã£o intacta! Apenas adicionar lÃ³gica de cache no inÃ­cio.

**PASSO 3.3: Adicionar salvamento no cache no final**

**Localizar** o `return stats` no final da funÃ§Ã£o mega_stats:

**ANTES:**
```python
    stats = {
        "today":     _count_bucket(db, tenantId, today_start, today_end, TZ),
        "week":      _count_bucket(db, tenantId, sunday_start, saturday_end, TZ),
        "month":     _count_bucket(db, tenantId, month_start, next_month_start, TZ),
        "nextMonth": _count_bucket(db, tenantId, next_month_start, after_next_month_start, TZ),
    }
    return stats
```

**DEPOIS:**
```python
    stats = {
        "today":     _count_bucket(db, tenantId, today_start, today_end, TZ),
        "week":      _count_bucket(db, tenantId, sunday_start, saturday_end, TZ),
        "month":     _count_bucket(db, tenantId, month_start, next_month_start, TZ),
        "nextMonth": _count_bucket(db, tenantId, next_month_start, after_next_month_start, TZ),
    }
    
    # Salvar no cache (thread-safe)
    with cache_lock:
        stats_cache[cache_key] = stats
    
    return stats
```

âœ… **Checkpoint:** Cache implementado no endpoint!

---

### PASSO 4: Validar Sintaxe

**PASSO 4.1: Verificar sintaxe Python**

```bash
cd backend
python -m py_compile routes/appointments.py
```

**Se houver erro:**
- Ler mensagem cuidadosamente
- Verificar indentaÃ§Ã£o
- Verificar imports
- Corrigir e repetir

**SaÃ­da esperada:**
```
(Nenhuma saÃ­da = sucesso!)
```

**PASSO 4.2: Verificar imports**

```bash
python -c "from cachetools import TTLCache; import threading; print('âœ… Imports OK')"
```

**SaÃ­da esperada:**
```
âœ… Imports OK
```

---

### PASSO 5: Testar ImplementaÃ§Ã£o

**PASSO 5.1: Reiniciar backend**

```bash
# Parar (Ctrl+C)
# Iniciar
uvicorn main:app --reload
```

**Verificar logs:**
```
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete.
```

**PASSO 5.2: Primeiro request (Cache MISS)**

```bash
curl -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant&tz=America/Recife"
```

**Verificar headers na resposta:**
```
HTTP/1.1 200 OK
X-Cache: MISS          â† Cache miss (primeira vez)
Cache-Control: no-store
...

{
  "today": {"confirmed": 3, "pending": 2},
  "week": {"confirmed": 15, "pending": 8},
  ...
}
```

âœ… **X-Cache: MISS** = Funcionando! Calculou e salvou no cache.

**PASSO 5.3: Segundo request (Cache HIT)**

**Imediatamente** fazer outro request:

```bash
curl -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant&tz=America/Recife"
```

**Verificar headers:**
```
HTTP/1.1 200 OK
X-Cache: HIT           â† Cache hit! ğŸ‰
Cache-Control: no-store
...

{
  "today": {"confirmed": 3, "pending": 2},
  ...
}
```

âœ… **X-Cache: HIT** = Retornou do cache (< 1ms)!

**PASSO 5.4: Aguardar TTL expirar**

Esperar 30 segundos e fazer novo request:

```bash
# Esperar 30s...
sleep 30

curl -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant&tz=America/Recife"
```

**Verificar:**
```
X-Cache: MISS    â† Cache expirou, recalculou
```

âœ… **TTL funcionando!** Cache expira apÃ³s 30s.

---

## ValidaÃ§Ã£o e Testes

### Checklist de ValidaÃ§Ã£o

#### âœ… Backend

- [ ] Servidor inicia sem erros
- [ ] Endpoint `/mega-stats` responde corretamente
- [ ] Primeiro request tem `X-Cache: MISS`
- [ ] Segundo request tem `X-Cache: HIT`
- [ ] Cache expira apÃ³s 30s
- [ ] Diferentes tenants tÃªm caches separados
- [ ] Diferentes timezones tÃªm caches separados

#### âœ… Performance

- [ ] Cache hit responde em < 1ms
- [ ] Cache miss responde em ~100ms
- [ ] MÃºltiplos requests usam cache compartilhado

### Testes Manuais Detalhados

#### TESTE 1: Verificar Cache Hit Rate

**Fazer 10 requests em sequÃªncia rÃ¡pida:**

```bash
for i in {1..10}; do
  echo "Request $i:"
  curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant" | grep X-Cache
  sleep 1
done
```

**Resultado esperado:**
```
Request 1: X-Cache: MISS
Request 2: X-Cache: HIT
Request 3: X-Cache: HIT
Request 4: X-Cache: HIT
...
Request 10: X-Cache: HIT
```

âœ… **Cache hit rate: 90%** (9/10 requests)

#### TESTE 2: Verificar Isolamento de Tenant

```bash
# Tenant 1
curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=tenant-1" | grep X-Cache
# Resultado: X-Cache: MISS

# Tenant 2 (diferente)
curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=tenant-2" | grep X-Cache
# Resultado: X-Cache: MISS  â† Correto! Cache separado por tenant

# Tenant 1 novamente
curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=tenant-1" | grep X-Cache
# Resultado: X-Cache: HIT   â† Cache do tenant-1 ainda vÃ¡lido
```

âœ… **Isolamento funcionando!**

#### TESTE 3: Verificar Timezone Separation

```bash
# Timezone 1
curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant&tz=America/Recife" | grep X-Cache
# Resultado: X-Cache: MISS

# Timezone 2 (diferente)
curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant&tz=America/Sao_Paulo" | grep X-Cache
# Resultado: X-Cache: MISS  â† Correto! Stats dependem de TZ
```

âœ… **Timezone isolation funcionando!**

#### TESTE 4: Verificar TTL Expiration

**Script de teste:**

```bash
#!/bin/bash
echo "Request 1 (Cache MISS esperado):"
curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant" | grep X-Cache

echo -e "\nRequest 2 imediato (Cache HIT esperado):"
curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant" | grep X-Cache

echo -e "\nAguardando 30s para TTL expirar..."
sleep 30

echo -e "\nRequest 3 apÃ³s TTL (Cache MISS esperado):"
curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant" | grep X-Cache
```

**Resultado esperado:**
```
Request 1 (Cache MISS esperado):
X-Cache: MISS

Request 2 imediato (Cache HIT esperado):
X-Cache: HIT

Aguardando 30s para TTL expirar...

Request 3 apÃ³s TTL (Cache MISS esperado):
X-Cache: MISS
```

âœ… **TTL funcionando perfeitamente!**

#### TESTE 5: Medir Performance

**Sem cache (desabilitar temporariamente):**

```bash
time curl -s "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant" > /dev/null
```

**Resultado:**
```
real    0m0.105s   â† ~100ms
```

**Com cache (apÃ³s um MISS inicial):**

```bash
# Primeiro: forÃ§ar cache
curl -s "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant" > /dev/null

# Segundo: medir cache hit
time curl -s "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant" > /dev/null
```

**Resultado:**
```
real    0m0.001s   â† ~1ms (100x mais rÃ¡pido!)
```

âœ… **Performance dramÃ¡tica:** Cache hit Ã© 100x mais rÃ¡pido!

#### TESTE 6: Frontend Dashboard

1. Abrir aplicaÃ§Ã£o: `http://localhost:5173`
2. Fazer login
3. Ver dashboard
4. Abrir DevTools > Network
5. Filtrar por "mega-stats"
6. Observar requests

**Esperado:**
- Primeiro request: `X-Cache: MISS` (~100ms)
- Requests seguintes (30s): `X-Cache: HIT` (~1ms)
- ApÃ³s 30s: `X-Cache: MISS` (TTL expirou)

### Teste de Carga

**Simular mÃºltiplos usuÃ¡rios:**

```bash
#!/bin/bash
# test_cache_load.sh

echo "Simulando 100 requests concorrentes..."

for i in {1..100}; do
  curl -s -i "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant" | grep X-Cache &
done

wait
echo "ConcluÃ­do!"
```

**Executar:**
```bash
chmod +x test_cache_load.sh
./test_cache_load.sh
```

**Resultado esperado:**
```
X-Cache: MISS   â† 1Âº request
X-Cache: HIT    â† 2Âº request
X-Cache: HIT    â† 3Âº request
...
X-Cache: HIT    â† 100Âº request

Cache Hit Rate: 99% (99/100)
```

ğŸ’¡ **Apenas 1 MISS** (primeiro), resto tudo HIT!

---

## Troubleshooting

### Erro: "ModuleNotFoundError: No module named 'cachetools'"

**Causa:** DependÃªncia nÃ£o instalada

**SoluÃ§Ã£o:**
```bash
cd backend
pip install cachetools==5.3.2
```

### Erro: "name 'stats_cache' is not defined"

**Causa:** VariÃ¡vel nÃ£o criada ou import faltando

**SoluÃ§Ã£o:** Verificar que cÃ³digo do PASSO 2.3 foi adicionado apÃ³s `router = ...`

### X-Cache sempre MISS (nunca HIT)

**Causa 1:** TTL muito curto ou cache nÃ£o estÃ¡ salvando

**Debug:**
```python
# Adicionar print temporÃ¡rio
print(f"Cache key: {cache_key}")
print(f"Cache size: {len(stats_cache)}")
print(f"Cache contents: {list(stats_cache.keys())}")
```

**Causa 2:** Requests muito espaÃ§ados (> 30s entre eles)

**SoluÃ§Ã£o:** Fazer requests em sequÃªncia rÃ¡pida (<5s intervalo)

### Cache Hit mas dados desatualizados

**Causa:** Esperado! Cache tem TTL de 30s

**SoluÃ§Ã£o:** 
- Se precisar de dados mais frescos, reduzir TTL:
  ```python
  stats_cache = TTLCache(maxsize=100, ttl=10)  # 10s ao invÃ©s de 30s
  ```
- Trade-off: Menos TTL = menos cache hits = menos performance gain

### Performance nÃ£o melhorou

**Causa:** Medindo cache MISS ao invÃ©s de HIT

**SoluÃ§Ã£o:** 
1. Fazer request inicial (MISS)
2. **Depois** medir segundo request (HIT)
3. HIT deve ser ~100x mais rÃ¡pido

### Header X-Cache nÃ£o aparece

**Causa:** CÃ³digo nÃ£o foi adicionado corretamente

**Verificar:**
```python
# Deve estar no cÃ³digo:
response.headers["X-Cache"] = "HIT"   # Dentro do if cached
response.headers["X-Cache"] = "MISS"  # Depois do if
```

### Cache cresce indefinidamente (memory leak)

**Causa:** TTLCache deve limpar automaticamente

**Verificar:**
```python
# Tamanho do cache
print(f"Cache size: {len(stats_cache)}")  # Deve ser < 100
```

**Se > 100:** Bug no TTLCache (raro), reiniciar servidor.

---

## Rollback

### Se algo deu errado

#### OpÃ§Ã£o 1: Reverter commit completo

```bash
git reset --hard HEAD~1
```

âš ï¸ **CUIDADO:** Perde TODAS as mudanÃ§as.

#### OpÃ§Ã£o 2: Reverter arquivos especÃ­ficos

```bash
# Reverter apenas appointments.py
git checkout HEAD -- backend/routes/appointments.py

# Reverter requirements.txt
git checkout HEAD -- backend/requirements.txt
```

#### OpÃ§Ã£o 3: Desabilitar cache manualmente

**Comentar cÃ³digo de cache:**

```python
# ============================================================================
# CACHE - P1-003 (DESABILITADO TEMPORARIAMENTE)
# ============================================================================

# stats_cache = TTLCache(maxsize=100, ttl=30)
# cache_lock = threading.Lock()
# def get_cache_key(...): ...

@router.get("/mega-stats")
def mega_stats(...):
    # Remover/comentar lÃ³gica de cache
    # cache_key = get_cache_key(tenantId, tz)
    # with cache_lock: ...
    
    # Ir direto para cÃ¡lculo
    response.headers["Cache-Control"] = "no-store"
    TZ = ZoneInfo(tz)
    # ... resto do cÃ³digo original ...
```

Salvar e reiniciar backend.

### Verificar estado apÃ³s rollback

```bash
git status
git diff backend/routes/appointments.py

# Testar endpoint
curl "http://localhost:8000/api/v1/appointments/mega-stats?tenantId=default-tenant"
```

---

## PrÃ³ximos Passos

### Melhorias Futuras

#### 1. Redis Cache (Multi-Server)

Quando migrar para mÃºltiplos servidores:

```python
# backend/cache.py
import redis
import json

redis_client = redis.Redis(
    host=os.getenv('REDIS_HOST', 'localhost'),
    port=int(os.getenv('REDIS_PORT', 6379)),
    db=0,
    decode_responses=True
)

def get_cached_stats(cache_key: str) -> dict | None:
    """Busca stats do Redis."""
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)
    return None

def set_cached_stats(cache_key: str, stats: dict, ttl: int = 30):
    """Salva stats no Redis com TTL."""
    redis_client.setex(
        cache_key,
        ttl,
        json.dumps(stats)
    )

# backend/routes/appointments.py
from cache import get_cached_stats, set_cached_stats

@router.get("/mega-stats")
def mega_stats(...):
    cache_key = get_cache_key(tenantId, tz)
    
    # Tentar Redis
    cached = get_cached_stats(cache_key)
    if cached:
        response.headers["X-Cache"] = "HIT"
        return cached
    
    # Cache miss - calcular
    stats = { ... }
    
    # Salvar no Redis
    set_cached_stats(cache_key, stats, ttl=30)
    
    return stats
```

**Vantagens Redis:**
- âœ… Compartilhado entre mÃºltiplos servidores
- âœ… Persiste ao reiniciar app
- âœ… Suporta invalidaÃ§Ã£o manual
- âœ… EscalÃ¡vel horizontalmente

#### 2. Cache Invalidation (Webhooks)

Invalidar cache quando dados mudam:

```python
# backend/routes/appointments.py

@router.post("/")
def create_appointment(...):
    # ... criar appointment ...
    
    # Invalidar cache do tenant
    cache_key_pattern = f"mega_stats:{appointment.tenantId}:*"
    
    # TTLCache (nÃ£o suporta pattern matching, limpar tudo do tenant)
    with cache_lock:
        keys_to_delete = [
            k for k in stats_cache.keys()
            if k.startswith(f"mega_stats:{appointment.tenantId}:")
        ]
        for key in keys_to_delete:
            del stats_cache[key]
    
    return db_appointment

@router.patch("/{appointment_id}")
def update_appointment(...):
    # ... atualizar ...
    
    # Invalidar cache
    # (mesmo cÃ³digo acima)
```

**Vantagens:**
- Dados sempre frescos apÃ³s mudanÃ§as
- NÃ£o precisa esperar TTL expirar
- Melhor UX

**Desvantagens:**
- Mais complexo
- Mais cÃ³digo
- Pode invalidar demais

#### 3. Cache Warming

Pre-popular cache para tenants ativos:

```python
# backend/cache_warmer.py
import asyncio
from datetime import datetime
from zoneinfo import ZoneInfo

async def warm_cache_for_tenant(tenant_id: str):
    """Pre-calcula stats para um tenant."""
    tz = "America/Recife"
    cache_key = get_cache_key(tenant_id, tz)
    
    # Verificar se jÃ¡ estÃ¡ no cache
    with cache_lock:
        if cache_key in stats_cache:
            return  # JÃ¡ warm
    
    # Calcular stats
    db = SessionLocal()
    try:
        # ... calcular stats ...
        stats = { ... }
        
        # Salvar no cache
        with cache_lock:
            stats_cache[cache_key] = stats
        
        print(f"âœ… Cache warmed for tenant {tenant_id}")
    finally:
        db.close()

async def warm_cache_periodically():
    """Roda a cada 25s para manter cache warm."""
    while True:
        active_tenants = ["default-tenant", "tenant-1", "tenant-2"]
        
        for tenant_id in active_tenants:
            await warm_cache_for_tenant(tenant_id)
        
        await asyncio.sleep(25)  # 25s (antes do TTL de 30s)

# Iniciar em background
@app.on_event("startup")
async def startup():
    asyncio.create_task(warm_cache_periodically())
```

**Vantagens:**
- Todos os requests sÃ£o cache HITs
- Performance consistente
- Ã“tima UX

**Desvantagens:**
- Usa recursos em background
- Mais complexo
- Pode calcular dados desnecessÃ¡rios

#### 4. Cache Metrics Dashboard

Monitorar performance do cache:

```python
# backend/cache_metrics.py
from dataclasses import dataclass
from datetime import datetime

@dataclass
class CacheMetrics:
    hits: int = 0
    misses: int = 0
    total_requests: int = 0
    hit_rate: float = 0.0
    avg_hit_time_ms: float = 0.0
    avg_miss_time_ms: float = 0.0

cache_metrics = CacheMetrics()

@router.get("/mega-stats")
def mega_stats(...):
    start_time = time.time()
    
    # ... lÃ³gica de cache ...
    
    duration_ms = (time.time() - start_time) * 1000
    
    if cache_hit:
        cache_metrics.hits += 1
        cache_metrics.avg_hit_time_ms = (
            (cache_metrics.avg_hit_time_ms * (cache_metrics.hits - 1) + duration_ms)
            / cache_metrics.hits
        )
    else:
        cache_metrics.misses += 1
        cache_metrics.avg_miss_time_ms = (
            (cache_metrics.avg_miss_time_ms * (cache_metrics.misses - 1) + duration_ms)
            / cache_metrics.misses
        )
    
    cache_metrics.total_requests += 1
    cache_metrics.hit_rate = (
        cache_metrics.hits / cache_metrics.total_requests * 100
    )
    
    return stats

@router.get("/cache-metrics")
def get_cache_metrics():
    """Endpoint de mÃ©tricas de cache."""
    return {
        "cache_stats": cache_metrics,
        "cache_size": len(stats_cache),
        "cache_keys": list(stats_cache.keys()),
    }
```

**Acessar mÃ©tricas:**
```bash
curl "http://localhost:8000/api/v1/appointments/cache-metrics"
```

**Resposta:**
```json
{
  "cache_stats": {
    "hits": 950,
    "misses": 50,
    "total_requests": 1000,
    "hit_rate": 95.0,
    "avg_hit_time_ms": 0.8,
    "avg_miss_time_ms": 102.5
  },
  "cache_size": 15,
  "cache_keys": [
    "mega_stats:default-tenant:America/Recife:2025-10-31",
    ...
  ]
}
```

### CorreÃ§Ãµes Relacionadas

ApÃ³s implementar P1-003, vocÃª tem:

- âœ… **P1-001:** PaginaÃ§Ã£o (menos dados por request)
- âœ… **P1-002:** N+1 fix (queries otimizadas)
- âœ… **P1-003:** Cache (95% menos queries)

**Resultado combinado:**
- PaginaÃ§Ã£o: 50 itens/pÃ¡gina ao invÃ©s de todos
- N+1 fix: 4 queries ao invÃ©s de 8
- Cache: 95% dos requests nÃ£o vÃ£o ao banco

**Total:** Sistema extremamente otimizado! ğŸš€

**PrÃ³xima recomendaÃ§Ã£o:**

**PERF-001:** Adicionar Ãndices Compostos  
**RazÃ£o:** Complementa perfeitamente as 3 otimizaÃ§Ãµes  
**Tempo:** 1 hora  
**Ganho adicional:** 50-90% em queries que vÃ£o ao banco

---

## ConclusÃ£o

### O Que Foi Implementado

âœ… **Cache TTL:**
- TTLCache com expiraÃ§Ã£o de 30s
- Thread-safe com locks
- Cache key por tenant + timezone + date

âœ… **Headers de Debug:**
- `X-Cache: HIT` - Request servido do cache
- `X-Cache: MISS` - Request calculou novo

âœ… **DocumentaÃ§Ã£o:**
- Docstring no endpoint
- ComentÃ¡rios explicativos
- FunÃ§Ã£o helper `get_cache_key`

### BenefÃ­cios AlcanÃ§ados

- ğŸš€ **Performance:** 100x mais rÃ¡pido (cache hit < 1ms)
- ğŸ’¾ **Carga no Banco:** 95% menos queries
- ğŸ“ˆ **Escalabilidade:** Suporta 100x mais usuÃ¡rios
- ğŸ’° **Custo:** Economia massiva em queries/IOPS
- ğŸ¯ **UX:** Respostas instantÃ¢neas

### MÃ©tricas de Sucesso

| MÃ©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| Queries/hora (100 users) | 48.000 | 2.400 | **-95%** |
| Tempo resposta (cache hit) | 100ms | 1ms | **-99%** |
| Cache hit rate | 0% | 60-95% | **+95%** |
| UsuÃ¡rios suportados | 100 | 10.000+ | **100x** |

### Impacto Real

**Antes (sem cache):**
```
100 usuÃ¡rios Ã— 120 requests/hora = 12.000 requests/hora
12.000 requests Ã— 4 queries = 48.000 queries/hora ao banco
```

**Depois (com cache):**
```
100 usuÃ¡rios Ã— 120 requests/hora = 12.000 requests/hora
95% cache hit = 11.400 requests do cache (0 queries)
5% cache miss = 600 requests Ã— 4 queries = 2.400 queries/hora
```

**Economia:** 45.600 queries/hora = **95% reduÃ§Ã£o!**

### PrÃ³xima CorreÃ§Ã£o Recomendada

**PERF-001:** Adicionar Ãndices Compostos  
**RazÃ£o:** Os 5% de cache misses ficarÃ£o ainda mais rÃ¡pidos  
**Tempo:** 1 hora  
**Impacto:** Alto (50-90% nos misses)

**Stack completo otimizado:**
1. âœ… P1-001: PaginaÃ§Ã£o
2. âœ… P1-002: N+1 fix  
3. âœ… P1-003: Cache
4. â­ï¸ PERF-001: Ãndices

= **Sistema production-ready!** ğŸ‰

---

## ReferÃªncias

- [MELHORIAS-E-CORRECOES.md](./MELHORIAS-E-CORRECOES.md#perf-002-falta-cache-em-endpoints-de-stats)
- [cachetools Documentation](https://cachetools.readthedocs.io/)
- [Python threading](https://docs.python.org/3/library/threading.html)
- [HTTP Caching Headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control)

---

**Documento gerado em:** Outubro 2025  
**Autor:** Sistema de DocumentaÃ§Ã£o AlignWork  
**VersÃ£o:** 1.0.0  
**Status:** âœ… Pronto para ImplementaÃ§Ã£o

---

## ApÃªndice: Diff Completo

### backend/requirements.txt

```diff
  fastapi==0.104.1
  uvicorn[standard]==0.24.0
  sqlalchemy==2.0.23
  pydantic==2.5.0
  python-jose[cryptography]==3.3.0
  passlib[bcrypt]==1.7.4
  python-multipart==0.0.6
+ cachetools==5.3.2
```

### backend/routes/appointments.py

```diff
  from fastapi import APIRouter, Depends, Query, Response, HTTPException
  from sqlalchemy.orm import Session
  from datetime import datetime, timedelta
  from zoneinfo import ZoneInfo
  from typing import List, Optional
  from auth.dependencies import get_db
  from models.appointment import Appointment
  from schemas.appointment import AppointmentCreate, AppointmentUpdate, AppointmentResponse, AppointmentPaginatedResponse
  from sqlalchemy import and_, func, case
+ from cachetools import TTLCache
+ import threading
  
  router = APIRouter(prefix="/v1/appointments", tags=["appointments"])
  
+ # ============================================================================
+ # CACHE - P1-003
+ # ============================================================================
+ 
+ stats_cache = TTLCache(maxsize=100, ttl=30)
+ cache_lock = threading.Lock()
+ 
+ def get_cache_key(tenant_id: str, tz: str) -> str:
+     """Gera chave de cache Ãºnica para mega_stats."""
+     now = datetime.now(ZoneInfo(tz))
+     date_key = now.strftime('%Y-%m-%d')
+     return f"mega_stats:{tenant_id}:{tz}:{date_key}"
  
  @router.get("/mega-stats")
  def mega_stats(
      response: Response,
      tenantId: str = Query(...),
      tz: str = Query("America/Recife"),
      db: Session = Depends(get_db),
  ):
+     """Retorna estatÃ­sticas agregadas com cache (TTL 30s)."""
+     cache_key = get_cache_key(tenantId, tz)
+     
+     # Tentar buscar do cache
+     with cache_lock:
+         cached = stats_cache.get(cache_key)
+         if cached is not None:
+             response.headers["Cache-Control"] = "no-store"
+             response.headers["X-Cache"] = "HIT"
+             return cached
+     
+     # Cache miss - calcular stats
+     response.headers["X-Cache"] = "MISS"
      response.headers["Cache-Control"] = "no-store"
  
      TZ = ZoneInfo(tz)
      now_local = datetime.now(TZ)
      
      # ... cÃ¡lculo dos buckets (inalterado) ...
      
      stats = {
          "today": _count_bucket(db, tenantId, today_start, today_end, TZ),
          "week": _count_bucket(db, tenantId, sunday_start, saturday_end, TZ),
          "month": _count_bucket(db, tenantId, month_start, next_month_start, TZ),
          "nextMonth": _count_bucket(db, tenantId, next_month_start, after_next_month_start, TZ),
      }
+     
+     # Salvar no cache
+     with cache_lock:
+         stats_cache[cache_key] = stats
      
      return stats
```

---

**FIM DO DOCUMENTO**

